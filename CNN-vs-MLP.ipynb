{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAI assignment-3, Q-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, save, load\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-5.1 Multi-digit Recognition on Multi-MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_train: (58000, 1, 28, 28) labels_train: (58000, 2)\n"
     ]
    }
   ],
   "source": [
    "#   Train dataset\n",
    "#  Specify the path to your data folder\n",
    "data_folder = 'C:/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/double_mnist_seed_123_image_size_64_64/train'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "# Loop through the subfolders, each representing a different class\n",
    "for class_folder in os.listdir(data_folder):\n",
    "    class_path = os.path.join(data_folder, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "    \n",
    "        # Loop through the images in the class folder\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.png'):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "\n",
    "                # Load the image using OpenCV and convert it to grayscale (if it's not already)\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Resize the image to 28x28 pixels\n",
    "                image = cv2.resize(image, (28, 28))\n",
    "\n",
    "                class12 = int(filename.split('_')[1].split('.')[0])\n",
    "                class1 = class12//10\n",
    "                class2 = class12 % 10\n",
    "                #filter out the same digit iamges\n",
    "                if (class1!=class2):\n",
    "                    labels.append([class1, class2])\n",
    "                    images.append(image)\n",
    "# Convert the lists to NumPy arrays and reshape the data\n",
    "images_train = np.array(images)\n",
    "labels_train = np.array(labels)\n",
    "images_train = images_train.reshape(images_train.shape[0], 1, 28, 28)\n",
    "\n",
    "# Optionally, you can normalize the pixel values to be between 0 and 1\n",
    "images_train = images_train / 255.0\n",
    "print('images_train:',images_train.shape,'labels_train:',labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display several images from the filtered dataset to familiarize yourself with\n",
    "the dual-digit nature of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x100 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,5, figsize = (5,1))\n",
    "sample_images = images_train[:5]\n",
    "for i in range(5):\n",
    "    axes[i].imshow(sample_images[i][0],'gray')\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_valid: (14000, 1, 28, 28) labels_valid: (14000, 2)\n"
     ]
    }
   ],
   "source": [
    "#   Validation dataset\n",
    "#  Specify the path to your data folder\n",
    "data_folder = 'C:/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/double_mnist_seed_123_image_size_64_64/val'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "# Loop through the subfolders, each representing a different class\n",
    "for class_folder in os.listdir(data_folder):\n",
    "    class_path = os.path.join(data_folder, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "    \n",
    "        # Loop through the images in the class folder\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.png'):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "\n",
    "                # Load the image using OpenCV and convert it to grayscale (if it's not already)\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Resize the image to 28x28 pixels\n",
    "                image = cv2.resize(image, (28, 28))\n",
    "\n",
    "                class12 = int(filename.split('_')[1].split('.')[0])\n",
    "                class1 = class12//10\n",
    "                class2 = class12 % 10\n",
    "                #filter out the same digit iamges\n",
    "                if (class1!=class2):\n",
    "                    labels.append([class1, class2])\n",
    "                    images.append(image)\n",
    "# Convert the lists to NumPy arrays and reshape the data\n",
    "images_valid = np.array(images)\n",
    "labels_valid = np.array(labels)\n",
    "images_valid = images_valid.reshape(images_valid.shape[0], 1, 28, 28)\n",
    "\n",
    "# Optionally, you can normalize the pixel values to be between 0 and 1\n",
    "images_valid = images_valid / 255.0\n",
    "print('images_valid:',images_valid.shape,'labels_valid:',labels_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_test: (18000, 1, 28, 28) labels_test: (18000, 2)\n"
     ]
    }
   ],
   "source": [
    "#  Test dataset\n",
    "#  Specify the path to your data folder\n",
    "data_folder = 'C:/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/double_mnist_seed_123_image_size_64_64/test'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "# Loop through the subfolders, each representing a different class\n",
    "for class_folder in os.listdir(data_folder):\n",
    "    class_path = os.path.join(data_folder, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "    \n",
    "        # Loop through the images in the class folder\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.png'):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "\n",
    "                # Load the image using OpenCV and convert it to grayscale (if it's not already)\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Resize the image to 28x28 pixels\n",
    "                image = cv2.resize(image, (28, 28))\n",
    "\n",
    "                class12 = int(filename.split('_')[1].split('.')[0])\n",
    "                class1 = class12//10\n",
    "                class2 = class12 % 10\n",
    "                #filter out the same digit iamges\n",
    "                if (class1!=class2):\n",
    "                    labels.append([class1, class2])\n",
    "                    images.append(image)\n",
    "# Convert the lists to NumPy arrays and reshape the data\n",
    "images_test = np.array(images)\n",
    "labels_test = np.array(labels)\n",
    "images_test = images_test.reshape(images_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# Optionally, you can normalize the pixel values to be between 0 and 1\n",
    "images_test = images_test / 255.0\n",
    "print('images_test:',images_test.shape,'labels_test:',labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 MLP on Multi-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement and train an MLP model on the MultiMNIST datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP model\n",
    "class FlexibleMLP(nn.Module):\n",
    "    def __init__(self, input_size=784, output_size=10, hidden_units_list = [128]):\n",
    "        super(FlexibleMLP, self).__init__()\n",
    "\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_units_list[0])\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_units_list) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_units_list[i], hidden_units_list[i+1]))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_units_list[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flatten(x, 1)  # Flatten the input if needed\n",
    "        x = self.input_layer(x)\n",
    "        \n",
    "        # Pass through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# # Example usage:\n",
    "# input_size = 784  # For MNIST (28x28)\n",
    "# output_size = 10  # Number of classes\n",
    "# hidden_units_list = [128, 64]  # List specifying the number of units in each hidden layer\n",
    "\n",
    "# # Create the flexible model\n",
    "# model = FlexibleMLP(input_size, output_size, hidden_units_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train_encoded = mlb.fit_transform(labels_train)\n",
    "images_train = images_train.astype('float32')\n",
    "train_x_n = images_train.reshape(images_train.shape[0], 28*28)\n",
    "train_x_n = torch.from_numpy(train_x_n)\n",
    "train_y_n = torch.from_numpy(labels_train_encoded)\n",
    "train_set = TensorDataset(train_x_n, train_y_n.type(torch.float32))\n",
    "\n",
    "#validation dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_valid_encoded = mlb.fit_transform(labels_valid)\n",
    "images_valid = images_valid.astype('float32')\n",
    "valid_x_n = images_valid.reshape(images_valid.shape[0], 28*28)\n",
    "valid_x_n = torch.from_numpy(valid_x_n)\n",
    "valid_y_n = torch.from_numpy(labels_valid_encoded)\n",
    "valid_set = TensorDataset(valid_x_n, valid_y_n)\n",
    "\n",
    "#test dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_test_encoded = mlb.fit_transform(labels_test)\n",
    "images_test = images_test.astype('float32')\n",
    "test_x_n = images_test.reshape(images_test.shape[0], 28*28)\n",
    "test_x_n = torch.from_numpy(test_x_n)\n",
    "test_y_n = torch.from_numpy(labels_test_encoded)\n",
    "test_set = TensorDataset(test_x_n, test_y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train MLP\n",
    "def train_mlp_model(hidden_units_list,epochs,batch_size,test_mode = False):\n",
    "    input_size=784\n",
    "    output_size=10\n",
    "    learning_rate = 0.001\n",
    "    model = FlexibleMLP(input_size, output_size, hidden_units_list)\n",
    "    dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(valid_set, batch_size=batch_size)\n",
    "    dataloader_test = DataLoader(test_set, batch_size=batch_size)\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #validation accuracy\n",
    "            total = 0\n",
    "            correct = 0\n",
    "        with torch.no_grad():\n",
    "            if (test_mode==False):\n",
    "                for data, target in dataloader_valid:\n",
    "                    output = model(data)\n",
    "                    output = 1 / (1 + np.exp(-output))\n",
    "                    # predicted = (output>0.5).int()\n",
    "                    top_indices = np.argsort(output, axis=1)[:, -2:]\n",
    "                    # Create a binary matrix where only the top 2 maximum values are set to 1\n",
    "                    predicted = np.zeros_like(output, dtype=int)\n",
    "                    row_indices = np.arange(output.shape[0])[:, np.newaxis]\n",
    "                    predicted[row_indices, top_indices] = 1\n",
    "                    # _, predicted = torch.max(output.data, 1)\n",
    "                    predicted = torch.from_numpy(predicted)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                acc = 100*correct/(total*len(dataloader_valid))\n",
    "            else:\n",
    "                for data, target in dataloader_test:\n",
    "                    output = model(data)\n",
    "                    output = 1 / (1 + np.exp(-output))\n",
    "                    # predicted = (output>0.5).int()\n",
    "                    top_indices = np.argsort(output, axis=1)[:, -2:]\n",
    "                    # Create a binary matrix where only the top 2 maximum values are set to 1\n",
    "                    predicted = np.zeros_like(output, dtype=int)\n",
    "                    row_indices = np.arange(output.shape[0])[:, np.newaxis]\n",
    "                    predicted[row_indices, top_indices] = 1\n",
    "                    # _, predicted = torch.max(output.data, 1)\n",
    "                    predicted = torch.from_numpy(predicted)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                acc = 100*correct/(total*len(dataloader_test))\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f},Accuracy: {acc}')\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'flexible_mlp_model.pth')\n",
    "    return acc,loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1         \n",
    "2. Hyperparameter Tuning: Adjust the number of hidden layers and the\n",
    "number of neurons within each layer to optimize performance and find\n",
    "the best model.           \n",
    "3. Report the accuracies on the train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\wandb\\run-20231023_184129-wbi5eu0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining/runs/wbi5eu0g' target=\"_blank\">likely-leaf-3</a></strong> to <a href='https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining/runs/wbi5eu0g' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining/runs/wbi5eu0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:0=([128], 8, 1000)\n",
      "Epoch [1/8], Loss: 4.2574,Accuracy: 52.2530612244898\n",
      "Epoch [2/8], Loss: 4.2174,Accuracy: 52.42448979591837\n",
      "Epoch [3/8], Loss: 4.1602,Accuracy: 52.59591836734694\n",
      "Epoch [4/8], Loss: 4.1457,Accuracy: 52.80816326530612\n",
      "Epoch [5/8], Loss: 4.1405,Accuracy: 52.71836734693878\n",
      "Epoch [6/8], Loss: 4.1175,Accuracy: 52.765306122448976\n",
      "Epoch [7/8], Loss: 4.1439,Accuracy: 52.84795918367347\n",
      "Epoch [8/8], Loss: 4.0870,Accuracy: 52.803061224489795\n",
      "Hyperparameters:1=([500, 200], 8, 1000)\n",
      "Epoch [1/8], Loss: 4.1172,Accuracy: 52.74387755102041\n",
      "Epoch [2/8], Loss: 3.9479,Accuracy: 53.621428571428574\n",
      "Epoch [3/8], Loss: 3.7886,Accuracy: 54.093877551020405\n",
      "Epoch [4/8], Loss: 3.6787,Accuracy: 54.85510204081633\n",
      "Epoch [5/8], Loss: 3.4467,Accuracy: 55.433673469387756\n",
      "Epoch [6/8], Loss: 3.3375,Accuracy: 55.683673469387756\n",
      "Epoch [7/8], Loss: 3.2364,Accuracy: 56.15204081632653\n",
      "Epoch [8/8], Loss: 3.1669,Accuracy: 56.6265306122449\n",
      "Hyperparameters:2=([128, 64], 8, 1000)\n",
      "Epoch [1/8], Loss: 4.2031,Accuracy: 52.3765306122449\n",
      "Epoch [2/8], Loss: 4.0921,Accuracy: 52.79795918367347\n",
      "Epoch [3/8], Loss: 3.9726,Accuracy: 53.70918367346939\n",
      "Epoch [4/8], Loss: 3.9638,Accuracy: 53.71632653061224\n",
      "Epoch [5/8], Loss: 3.9312,Accuracy: 54.00204081632653\n",
      "Epoch [6/8], Loss: 3.8804,Accuracy: 54.029591836734696\n",
      "Epoch [7/8], Loss: 3.8253,Accuracy: 54.333673469387755\n",
      "Epoch [8/8], Loss: 3.7464,Accuracy: 54.41530612244898\n",
      "Hyperparameters:3=([256, 128], 8, 1000)\n",
      "Epoch [1/8], Loss: 4.1430,Accuracy: 52.21224489795918\n",
      "Epoch [2/8], Loss: 4.1120,Accuracy: 53.22551020408163\n",
      "Epoch [3/8], Loss: 3.9571,Accuracy: 53.68265306122449\n",
      "Epoch [4/8], Loss: 3.9079,Accuracy: 54.160204081632656\n",
      "Epoch [5/8], Loss: 3.7185,Accuracy: 54.49183673469388\n",
      "Epoch [6/8], Loss: 3.6650,Accuracy: 54.9030612244898\n",
      "Epoch [7/8], Loss: 3.5247,Accuracy: 55.059183673469384\n",
      "Epoch [8/8], Loss: 3.4854,Accuracy: 55.53877551020408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>▁▃▆█</td></tr><tr><td>accuracy</td><td>▁█▄▆</td></tr><tr><td>loss</td><td>█▁▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>3</td></tr><tr><td>accuracy</td><td>55.53878</td></tr><tr><td>loss</td><td>3.48545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-leaf-3</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining/runs/wbi5eu0g' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.1%20MLP%20on%20Multi-MNIST%20dataset%20hyperparameters%20tunining/runs/wbi5eu0g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_184129-wbi5eu0g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(project=\"Q-5.1.1 MLP on Multi-MNIST dataset hyperparameters tunining\")\n",
    "\n",
    "from itertools import product\n",
    "h_param = {\n",
    "        'hidden_units_list': [[128], [500,200], [128,64], [256,128]],\n",
    "        'epochs' : [8],\n",
    "        'batch_size': [1000]\n",
    "        }\n",
    "hyper_param = list(product(*h_param.values()))\n",
    "J=0\n",
    "accuracy = []\n",
    "for i in hyper_param:\n",
    "    print(f'Hyperparameters:{J}={i}')\n",
    "    acc ,loss= train_mlp_model(i[0],i[1],i[2])\n",
    "    wandb.log({\"Hyper parameters pair\":J,\"accuracy\": acc, \"loss\": loss})\n",
    "    \n",
    "    J += 1\n",
    "    accuracy.append(acc)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy1=56.6265306122449 \n",
      "We get this accuracy for this hyperparameters\n",
      "(hidden_units_list,epochs,batch_size): ([500, 200], 8, 1000).\n"
     ]
    }
   ],
   "source": [
    "# Max_accu_hy_param_index = 56\n",
    "Max_accu_hy_param_index = np.argmax(accuracy)\n",
    "# print(f\"We get this accuracy for this hyperparameters\\n(hidden_units_list,epochs,batch_size): {hyper_param[Max_accu_hy_param_index]}.\")\n",
    "print(f\"The maximum accuracy{Max_accu_hy_param_index}={accuracy[Max_accu_hy_param_index]} \\nWe get this accuracy for this hyperparameters\\n(hidden_units_list,epochs,batch_size): {hyper_param[Max_accu_hy_param_index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1       \n",
    "4. Evaluate your trained model on test set and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:4=([500, 200], 8, 1000)\n",
      "Epoch [1/8], Loss: 4.1587,Accuracy: 40.443827160493825\n",
      "Epoch [2/8], Loss: 4.0021,Accuracy: 41.2679012345679\n",
      "Epoch [3/8], Loss: 3.8311,Accuracy: 41.970987654320986\n",
      "Epoch [4/8], Loss: 3.6614,Accuracy: 42.79382716049383\n",
      "Epoch [5/8], Loss: 3.4484,Accuracy: 43.69444444444444\n",
      "Epoch [6/8], Loss: 3.3044,Accuracy: 43.88703703703704\n",
      "Epoch [7/8], Loss: 3.2393,Accuracy: 44.269753086419755\n",
      "Epoch [8/8], Loss: 3.1038,Accuracy: 44.5679012345679\n",
      "Accuracy and loss on the test dataset for best hyperparameters is : 44.5679012345679 3.103806972503662\n"
     ]
    }
   ],
   "source": [
    "i = hyper_param[Max_accu_hy_param_index]\n",
    "print(f'Hyperparameters:{J}={i}')\n",
    "acc ,loss= train_mlp_model(i[0],i[1],i[2],test_mode=True)\n",
    "print(\"Accuracy and loss on the test dataset for best hyperparameters is :\",acc,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 CNN on Multi-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design and train a CNN model on the MultiMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class MY_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self,kernel_size = (3,3),stride = (1,1), dropout_rate = 0.25):\n",
    "        super(MY_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size,stride=stride, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d((2,2),stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size,stride=stride, padding=1)\n",
    "      \n",
    "        out1 =  int(self.calculate_out(28, kernel_size, stride)/2)\n",
    "        self.out = int(self.calculate_out(out1, kernel_size, stride)/2)\n",
    "     \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out_features = 64*self.out*self.out\n",
    "        self.fc = nn.Linear(self.out_features,10)   #(out_features,in_features)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def calculate_out(self, input_size, kernel_size, stride):\n",
    "            return ((input_size + 2 - (kernel_size[0] - 1) - 1) / stride[0]) + 1\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))    #N,32,28,28\n",
    "        x = self.pool(x)                #N,32,14,14\n",
    "        x = self.relu(self.conv2(x))    #N,64,14,14\n",
    "        x = self.pool(x)                #N,64,7,7\n",
    "\n",
    "        x = x.view(-1,self.out_features) #N,64*7*7\n",
    "        x = self.dropout(x)              #N,64*7*7\n",
    "        x = self.fc(x)                  #N,10\n",
    "        # x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN_model(learning_rate, epochs, batch_size, kernel_size, stride, dropout_rate, test_mode=False):\n",
    "    model = MY_CNN(kernel_size, stride, dropout_rate)\n",
    "    dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(valid_set, batch_size=batch_size)\n",
    "    dataloader_test = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(dataloader_train)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(dataloader_train):\n",
    "            # images = images.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            total=0\n",
    "            correct=0\n",
    "        #Accuracy calculaltion:\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            if(test_mode==False):\n",
    "              n_samples = len(dataloader_valid.dataset)\n",
    "              for images, labels in dataloader_valid:\n",
    "\n",
    "                #   images = images.to(device)\n",
    "                #   labels = labels.to(device)\n",
    "                output = model(images)\n",
    "                output = 1 / (1 + np.exp(-output))\n",
    "              \n",
    "                top_indices = np.argsort(output, axis=1)[:, -2:]\n",
    "                # Create a binary matrix where only the top 2 maximum values are set to 1\n",
    "                predicted = np.zeros_like(output, dtype=int)\n",
    "                row_indices = np.arange(output.shape[0])[:, np.newaxis]\n",
    "                predicted[row_indices, top_indices] = 1\n",
    "                # _, predicted = torch.max(output.data, 1)\n",
    "                predicted = torch.from_numpy(predicted)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "              acc = 100*correct/(total*len(dataloader_valid))\n",
    "            else:\n",
    "              \n",
    "              for images, labels in dataloader_test:\n",
    "\n",
    "                # images = images.to(device)\n",
    "                # labels = labels.to(device)\n",
    "                output = model(images)\n",
    "                output = 1 / (1 + np.exp(-output))\n",
    "\n",
    "                top_indices = np.argsort(output, axis=1)[:, -2:]\n",
    "                # Create a binary matrix where only the top 2 maximum values are set to 1\n",
    "                predicted = np.zeros_like(output, dtype=int)\n",
    "                row_indices = np.arange(output.shape[0])[:, np.newaxis]\n",
    "                predicted[row_indices, top_indices] = 1\n",
    "            \n",
    "                predicted = torch.from_numpy(predicted)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "              acc = 100*correct/(total*len(dataloader_valid))\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f},Accuracy: {acc}')\n",
    "\n",
    "    PATH = './Q_5_cnn.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    return acc, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58000, 1, 28, 28)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train_encoded = mlb.fit_transform(labels_train)\n",
    "train_x_n = images_train.astype('float32')\n",
    "# train_x_n = images_train.reshape(images_train.shape[0], 28*28)\n",
    "train_x_n = torch.from_numpy(train_x_n)\n",
    "train_y_n = torch.from_numpy(labels_train_encoded)\n",
    "train_set = TensorDataset(train_x_n, train_y_n.type(torch.float32))\n",
    "\n",
    "#validation dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_valid_encoded = mlb.fit_transform(labels_valid)\n",
    "valid_x_n = images_valid.astype('float32')\n",
    "# valid_x_n = images_valid.reshape(images_valid.shape[0], 28*28)\n",
    "valid_x_n = torch.from_numpy(valid_x_n)\n",
    "valid_y_n = torch.from_numpy(labels_valid_encoded)\n",
    "valid_set = TensorDataset(valid_x_n, valid_y_n)\n",
    "\n",
    "#test dataset preprocessing\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_test_encoded = mlb.fit_transform(labels_test)\n",
    "test_x_n = images_test.astype('float32')\n",
    "# test_x_n = images_test.reshape(images_test.shape[0], 28*28)\n",
    "test_x_n = torch.from_numpy(test_x_n)\n",
    "test_y_n = torch.from_numpy(labels_test_encoded)\n",
    "test_set = TensorDataset(test_x_n, test_y_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.2          \n",
    "2. Hyperparameter Tuning: Experiment with different learning rates, kernel\n",
    "sizes, and dropout rates to determine the optimal configuration.   \n",
    "3. Report the accuracies on the train and validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ru6sc3w4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-gorge-2</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/ru6sc3w4' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/ru6sc3w4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_192619-ru6sc3w4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ru6sc3w4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\wandb\\run-20231023_192930-4y28uz9f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/4y28uz9f' target=\"_blank\">dutiful-glitter-3</a></strong> to <a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/4y28uz9f' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/4y28uz9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:0=(0.005, 8, 1000, (3, 3), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 4.5180,Accuracy: 49.21632653061224\n",
      "Epoch [2/8], Loss: 4.1153,Accuracy: 53.234693877551024\n",
      "Epoch [3/8], Loss: 3.9659,Accuracy: 54.316326530612244\n",
      "Epoch [4/8], Loss: 3.8964,Accuracy: 54.10918367346939\n",
      "Epoch [5/8], Loss: 3.6547,Accuracy: 55.44795918367347\n",
      "Epoch [6/8], Loss: 3.5370,Accuracy: 56.35510204081633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:08.443474, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/8], Loss: 3.3998,Accuracy: 56.51734693877551\n",
      "Epoch [8/8], Loss: 3.3286,Accuracy: 56.29387755102041\n",
      "Hyperparameters:1=(0.005, 8, 1000, (3, 3), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 4.2894,Accuracy: 52.1530612244898\n",
      "Epoch [2/8], Loss: 3.7434,Accuracy: 54.97244897959184\n",
      "Epoch [3/8], Loss: 3.5973,Accuracy: 55.87244897959184\n",
      "Epoch [4/8], Loss: 3.4161,Accuracy: 56.391836734693875\n",
      "Epoch [5/8], Loss: 3.3055,Accuracy: 56.76428571428571\n",
      "Epoch [6/8], Loss: 3.2471,Accuracy: 57.073469387755104\n",
      "Epoch [7/8], Loss: 3.1647,Accuracy: 57.255102040816325\n",
      "Epoch [8/8], Loss: 3.1270,Accuracy: 57.3\n",
      "Hyperparameters:2=(0.005, 8, 1000, (5, 5), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 3.7243,Accuracy: 55.09795918367347\n",
      "Epoch [2/8], Loss: 3.3187,Accuracy: 56.48877551020408\n",
      "Epoch [3/8], Loss: 3.1006,Accuracy: 57.398979591836735\n",
      "Epoch [4/8], Loss: 3.0037,Accuracy: 57.36938775510204\n",
      "Epoch [5/8], Loss: 2.9322,Accuracy: 57.85510204081633\n",
      "Epoch [6/8], Loss: 2.8544,Accuracy: 58.29387755102041\n",
      "Epoch [7/8], Loss: 2.7831,Accuracy: 58.423469387755105\n",
      "Epoch [8/8], Loss: 2.8050,Accuracy: 58.573469387755104\n",
      "Hyperparameters:3=(0.005, 8, 1000, (5, 5), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 4.2812,Accuracy: 51.61326530612245\n",
      "Epoch [2/8], Loss: 4.1051,Accuracy: 52.35408163265306\n",
      "Epoch [3/8], Loss: 3.9686,Accuracy: 51.69387755102041\n",
      "Epoch [4/8], Loss: 3.8587,Accuracy: 51.83469387755102\n",
      "Epoch [5/8], Loss: 3.8350,Accuracy: 51.9969387755102\n",
      "Epoch [6/8], Loss: 3.7842,Accuracy: 52.2469387755102\n",
      "Epoch [7/8], Loss: 3.7504,Accuracy: 52.02857142857143\n",
      "Epoch [8/8], Loss: 3.5616,Accuracy: 53.29897959183673\n",
      "Hyperparameters:4=(0.001, 8, 1000, (3, 3), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 4.0529,Accuracy: 53.75612244897959\n",
      "Epoch [2/8], Loss: 3.3681,Accuracy: 57.2234693877551\n",
      "Epoch [3/8], Loss: 3.0331,Accuracy: 59.316326530612244\n",
      "Epoch [4/8], Loss: 2.8713,Accuracy: 60.173469387755105\n",
      "Epoch [5/8], Loss: 2.7799,Accuracy: 60.88979591836735\n",
      "Epoch [6/8], Loss: 2.7204,Accuracy: 61.45816326530612\n",
      "Epoch [7/8], Loss: 2.6311,Accuracy: 61.80408163265306\n",
      "Epoch [8/8], Loss: 2.6001,Accuracy: 61.933673469387756\n",
      "Hyperparameters:5=(0.001, 8, 1000, (3, 3), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 4.0642,Accuracy: 53.012244897959185\n",
      "Epoch [2/8], Loss: 3.4478,Accuracy: 57.44183673469388\n",
      "Epoch [3/8], Loss: 3.0501,Accuracy: 59.005102040816325\n",
      "Epoch [4/8], Loss: 2.9066,Accuracy: 60.0265306122449\n",
      "Epoch [5/8], Loss: 2.8000,Accuracy: 60.816326530612244\n",
      "Epoch [6/8], Loss: 2.6999,Accuracy: 61.13061224489796\n",
      "Epoch [7/8], Loss: 2.6148,Accuracy: 61.553061224489795\n",
      "Epoch [8/8], Loss: 2.5813,Accuracy: 61.80816326530612\n",
      "Hyperparameters:6=(0.001, 8, 1000, (5, 5), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 3.9227,Accuracy: 54.14387755102041\n",
      "Epoch [2/8], Loss: 3.2099,Accuracy: 58.9030612244898\n",
      "Epoch [3/8], Loss: 2.8444,Accuracy: 60.09795918367347\n",
      "Epoch [4/8], Loss: 2.6734,Accuracy: 60.553061224489795\n",
      "Epoch [5/8], Loss: 2.5614,Accuracy: 61.077551020408166\n",
      "Epoch [6/8], Loss: 2.5292,Accuracy: 61.78469387755102\n",
      "Epoch [7/8], Loss: 2.4424,Accuracy: 61.720408163265304\n",
      "Epoch [8/8], Loss: 2.3914,Accuracy: 61.99183673469388\n",
      "Hyperparameters:7=(0.001, 8, 1000, (5, 5), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 3.9410,Accuracy: 53.922448979591834\n",
      "Epoch [2/8], Loss: 3.3244,Accuracy: 57.75204081632653\n",
      "Epoch [3/8], Loss: 2.9723,Accuracy: 59.53775510204082\n",
      "Epoch [4/8], Loss: 2.7065,Accuracy: 61.114285714285714\n",
      "Epoch [5/8], Loss: 2.5967,Accuracy: 61.114285714285714\n",
      "Epoch [6/8], Loss: 2.5277,Accuracy: 61.436734693877554\n",
      "Epoch [7/8], Loss: 2.4488,Accuracy: 61.813265306122446\n",
      "Epoch [8/8], Loss: 2.3846,Accuracy: 61.63061224489796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>accuracy</td><td>▃▄▅▁████</td></tr><tr><td>loss</td><td>▇▅▄█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>7</td></tr><tr><td>accuracy</td><td>61.63061</td></tr><tr><td>loss</td><td>2.38458</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-glitter-3</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/4y28uz9f' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.1.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Multi-MNIST%20dataset/runs/4y28uz9f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_192930-4y28uz9f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(project=\"Q-5.1.2 Hyperparameters tunining of CNN for Multi-MNIST dataset\")\n",
    "\n",
    "from itertools import product\n",
    "h_param = {\n",
    "        'learning_rate': [0.005, 0.001],\n",
    "        'epochs' : [8],\n",
    "        'batch_size': [1000],\n",
    "        'kernel_sizes' : [(3,3),(5,5)],\n",
    "        'strides' : [(1,1)],\n",
    "        'dropout_rate' : [0.15,0.25]\n",
    "        }\n",
    "hyper_param = list(product(*h_param.values()))\n",
    "J=0\n",
    "accuracy = []\n",
    "for i in hyper_param:\n",
    "    print(f'Hyperparameters:{J}={i}')\n",
    "    acc ,loss = train_CNN_model(i[0], i[1], i[2], i[3], i[4], i[5])\n",
    "    wandb.log({\"Hyper parameters pair\":J,\"accuracy\": acc, \"loss\": loss})\n",
    "    \n",
    "    J += 1\n",
    "    accuracy.append(acc)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy6 = 61.99183673469388\n",
      "We get this accuracy for this hyperparameters\n",
      "(learning_rate,epochs,batch_size,kernel_sizes,strides,dropout_rate): (0.001, 8, 1000, (5, 5), (1, 1), 0.15).\n"
     ]
    }
   ],
   "source": [
    "Max_accu_hy_param_index = 56\n",
    "Max_accu_hy_param_index = np.argmax(accuracy)\n",
    "print(f\"The maximum accuracy{Max_accu_hy_param_index} = {accuracy[Max_accu_hy_param_index]}\")\n",
    "print(f\"We get this accuracy for this hyperparameters\\n(learning_rate,epochs,batch_size,kernel_sizes,strides,dropout_rate): {hyper_param[Max_accu_hy_param_index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.2     \n",
    "4. Evaluate your trained model on test set and report the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:8=(0.001, 8, 1000, (5, 5), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 3.8637,Accuracy: 54.55612244897959\n",
      "Epoch [2/8], Loss: 3.3018,Accuracy: 58.26938775510204\n",
      "Epoch [3/8], Loss: 2.9666,Accuracy: 60.022448979591836\n",
      "Epoch [4/8], Loss: 2.6951,Accuracy: 60.48877551020408\n",
      "Epoch [5/8], Loss: 2.5584,Accuracy: 60.618367346938776\n",
      "Epoch [6/8], Loss: 2.4614,Accuracy: 61.41122448979592\n",
      "Epoch [7/8], Loss: 2.4232,Accuracy: 61.659183673469386\n",
      "Epoch [8/8], Loss: 2.3761,Accuracy: 61.94387755102041\n",
      "Accuracy and loss on the test dataset for best hyperparameters is :\n",
      "Accuracy: 61.94387755102041  Loss: 2.3761250972747803\n"
     ]
    }
   ],
   "source": [
    "i = hyper_param[Max_accu_hy_param_index]\n",
    "print(f'Hyperparameters:{J}={i}')\n",
    "acc ,loss = train_CNN_model(i[0], i[1], i[2], i[3], i[4], i[5])\n",
    "print(f\"Accuracy and loss on the test dataset for best hyperparameters is :\")\n",
    "print(\"Accuracy:\",acc,\" Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-5.2 Permuted MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape: (60000, 28, 28) train_labels.shape: (60000,) \n",
      "test_images.shape: (10000, 28, 28) test_labels.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('permuted_mnist.npz')\n",
    "train_images_n = data['train_images']\n",
    "train_labels_n = data['train_labels']\n",
    "test_images = data['test_images']\n",
    "test_labels = data['test_labels']\n",
    "print('train_images.shape:',train_images_n.shape,\"train_labels.shape:\",train_labels_n.shape, \n",
    "'\\ntest_images.shape:', test_images.shape,\"test_labels.shape:\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x100 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Samples visulization\n",
    "fig, axes = plt.subplots(1,5, figsize = (5,1))\n",
    "sample_images = train_images_n[:5]\n",
    "for i in range(5):\n",
    "    axes[i].imshow(sample_images[i],'gray')\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train, test and validaton data: (50000, 28, 28) (10000, 28, 28) (10000, 28, 28)\n",
      "Shape of the train, test and validaton label: (50000,) (10000, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#separate the training, testing and validation data\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(train_images_n,train_labels_n,test_size=0.16666,random_state=1)\n",
    "print(\"Shape of the train, test and validaton data:\",train_images.shape,test_images.shape,valid_images.shape)\n",
    "print(\"Shape of the train, test and validaton label:\",train_labels.shape,test_labels.shape,valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 MLP on Permuted-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset preprocessing\n",
    "train_labels = train_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train_encoded = mlb.fit_transform(train_labels)\n",
    "train_images = train_images.astype('float32')\n",
    "train_x_n = train_images.reshape(train_images.shape[0], 28*28)\n",
    "train_x_n = torch.from_numpy(train_x_n)\n",
    "train_y_n = torch.from_numpy(labels_train_encoded)\n",
    "train_set = TensorDataset(train_x_n, train_y_n.type(torch.float32))\n",
    "\n",
    "#validation dataset preprocessing\n",
    "valid_labels = valid_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_valid_encoded = mlb.fit_transform(valid_labels)\n",
    "valid_images = valid_images.astype('float32')\n",
    "valid_x_n = valid_images.reshape(valid_images.shape[0], 28*28)\n",
    "valid_x_n = torch.from_numpy(valid_x_n)\n",
    "valid_y_n = torch.from_numpy(labels_valid_encoded)\n",
    "valid_set = TensorDataset(valid_x_n, valid_y_n)\n",
    "\n",
    "#test dataset preprocessing\n",
    "test_labels = test_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_test_encoded = mlb.fit_transform(test_labels)\n",
    "test_images = test_images.astype('float32')\n",
    "test_x_n = test_images.reshape(test_images.shape[0], 28*28)\n",
    "test_x_n = torch.from_numpy(test_x_n)\n",
    "test_y_n = torch.from_numpy(labels_test_encoded)\n",
    "test_set = TensorDataset(test_x_n, test_y_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.1 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ngce3s62) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-frost-1</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/ngce3s62' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/ngce3s62</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_220323-ngce3s62\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ngce3s62). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\wandb\\run-20231023_220350-grl1k00w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/grl1k00w' target=\"_blank\">lilac-elevator-2</a></strong> to <a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/grl1k00w' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/grl1k00w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:0=([128], 8, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JANAKSINH\\AppData\\Local\\Temp\\ipykernel_6780\\1314646254.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  output = 1 / (1 + np.exp(-output))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 2.5434,Accuracy: 79.074\n",
      "Epoch [2/8], Loss: 1.9751,Accuracy: 79.558\n",
      "Epoch [3/8], Loss: 1.1823,Accuracy: 81.422\n",
      "Epoch [4/8], Loss: 1.0350,Accuracy: 83.956\n",
      "Epoch [5/8], Loss: 0.7728,Accuracy: 84.692\n",
      "Epoch [6/8], Loss: 0.7991,Accuracy: 84.526\n",
      "Epoch [7/8], Loss: 0.8245,Accuracy: 85.184\n",
      "Epoch [8/8], Loss: 0.7778,Accuracy: 85.586\n",
      "Hyperparameters:1=([128, 64], 8, 1000)\n",
      "Epoch [1/8], Loss: 0.3932,Accuracy: 88.906\n",
      "Epoch [2/8], Loss: 0.2690,Accuracy: 89.272\n",
      "Epoch [3/8], Loss: 0.1779,Accuracy: 89.384\n",
      "Epoch [4/8], Loss: 0.2018,Accuracy: 89.482\n",
      "Epoch [5/8], Loss: 0.1526,Accuracy: 89.546\n",
      "Epoch [6/8], Loss: 0.1902,Accuracy: 89.596\n",
      "Epoch [7/8], Loss: 0.1522,Accuracy: 89.624\n",
      "Epoch [8/8], Loss: 0.1174,Accuracy: 89.65\n",
      "Hyperparameters:2=([256, 128], 8, 1000)\n",
      "Epoch [1/8], Loss: 0.3195,Accuracy: 89.242\n",
      "Epoch [2/8], Loss: 0.2219,Accuracy: 89.442\n",
      "Epoch [3/8], Loss: 0.1723,Accuracy: 89.538\n",
      "Epoch [4/8], Loss: 0.1458,Accuracy: 89.61\n",
      "Epoch [5/8], Loss: 0.1436,Accuracy: 89.62\n",
      "Epoch [6/8], Loss: 0.0909,Accuracy: 89.666\n",
      "Epoch [7/8], Loss: 0.0899,Accuracy: 89.692\n",
      "Epoch [8/8], Loss: 0.0709,Accuracy: 89.69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>▁▅█</td></tr><tr><td>accuracy</td><td>▁██</td></tr><tr><td>loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Hyper parameters pair</td><td>2</td></tr><tr><td>accuracy</td><td>89.69</td></tr><tr><td>loss</td><td>0.07086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-elevator-2</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/grl1k00w' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.1%20MLP%20on%20Permuted-MNIST%20dataset%20hyperparameters%20tunining/runs/grl1k00w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_220350-grl1k00w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(project=\"Q-5.2.1 MLP on Permuted-MNIST dataset hyperparameters tunining\")\n",
    "\n",
    "from itertools import product\n",
    "h_param = {\n",
    "        'hidden_units_list': [[128], [128,64], [256,128]],\n",
    "        'epochs' : [8],\n",
    "        'batch_size': [1000]\n",
    "        }\n",
    "hyper_param = list(product(*h_param.values()))\n",
    "J=0\n",
    "accuracy = []\n",
    "for i in hyper_param:\n",
    "    print(f'Hyperparameters:{J}={i}')\n",
    "    acc ,loss= train_mlp_model(i[0],i[1],i[2])\n",
    "    wandb.log({\"Hyper parameters pair\":J,\"accuracy\": acc, \"loss\": loss})\n",
    "    \n",
    "    J += 1\n",
    "    accuracy.append(acc)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy2=89.69 \n",
      "We get this accuracy for this hyperparameters\n",
      "(hidden_units_list,epochs,batch_size): ([256, 128], 8, 1000).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Max_accu_hy_param_index = np.argmax(accuracy)\n",
    "print(f\"The maximum accuracy{Max_accu_hy_param_index}={accuracy[Max_accu_hy_param_index]} \\nWe get this accuracy for this hyperparameters\\n(hidden_units_list,epochs,batch_size): {hyper_param[Max_accu_hy_param_index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.1 Evaluate the model for best hyperpameter on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:3=([256, 128], 8, 1000)\n",
      "Epoch [1/8], Loss: 0.3279,Accuracy: 89.262\n",
      "Epoch [2/8], Loss: 0.2415,Accuracy: 89.534\n",
      "Epoch [3/8], Loss: 0.1737,Accuracy: 89.596\n",
      "Epoch [4/8], Loss: 0.1305,Accuracy: 89.688\n",
      "Epoch [5/8], Loss: 0.1002,Accuracy: 89.724\n",
      "Epoch [6/8], Loss: 0.0859,Accuracy: 89.74\n",
      "Epoch [7/8], Loss: 0.1128,Accuracy: 89.744\n",
      "Epoch [8/8], Loss: 0.0556,Accuracy: 89.728\n",
      "Accuracy and loss on the test dataset for best hyperparameters is :\n",
      "Accuracy: 89.728  Loss: 0.055619820952415466\n"
     ]
    }
   ],
   "source": [
    "i = hyper_param[Max_accu_hy_param_index]\n",
    "print(f'Hyperparameters:{J}={i}')\n",
    "acc ,loss= train_mlp_model(i[0],i[1],i[2],test_mode=True)\n",
    "print(f\"Accuracy and loss on the test dataset for best hyperparameters is :\")\n",
    "print(\"Accuracy:\",acc,\" Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2  CNN on Permuted-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset preprocessing\n",
    "train_labels = train_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train_encoded = mlb.fit_transform(train_labels)\n",
    "train_x_n = train_images.astype('float32')\n",
    "train_x_n = train_images.reshape(train_images.shape[0],1, 28,28)\n",
    "train_x_n = torch.from_numpy(train_x_n)\n",
    "train_y_n = torch.from_numpy(labels_train_encoded)\n",
    "train_set = TensorDataset(train_x_n, train_y_n.type(torch.float32))\n",
    "\n",
    "#validation dataset preprocessing\n",
    "valid_labels = valid_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_valid_encoded = mlb.fit_transform(valid_labels)\n",
    "valid_x_n = valid_images.astype('float32')\n",
    "valid_x_n = valid_images.reshape(valid_images.shape[0],1, 28,28)\n",
    "valid_x_n = torch.from_numpy(valid_x_n)\n",
    "valid_y_n = torch.from_numpy(labels_valid_encoded)\n",
    "valid_set = TensorDataset(valid_x_n, valid_y_n)\n",
    "\n",
    "#test dataset preprocessing\n",
    "test_labels = test_labels.reshape(-1,1)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_test_encoded = mlb.fit_transform(test_labels)\n",
    "test_x_n = test_images.astype('float32')\n",
    "test_x_n = test_images.reshape(test_images.shape[0],1, 28,28)\n",
    "test_x_n = torch.from_numpy(test_x_n)\n",
    "test_y_n = torch.from_numpy(labels_test_encoded)\n",
    "test_set = TensorDataset(test_x_n, test_y_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cg2w6h3r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-field-2</strong> at: <a href='https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset/runs/cg2w6h3r' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset/runs/cg2w6h3r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231023_222746-cg2w6h3r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cg2w6h3r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\wandb\\run-20231023_223345-7q0c5wey</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset/runs/7q0c5wey' target=\"_blank\">scarlet-lion-3</a></strong> to <a href='https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset/runs/7q0c5wey' target=\"_blank\">https://wandb.ai/janaksinhven/Q-5.2.2%20Hyperparameters%20tunining%20of%20CNN%20for%20Permuted-MNIST%20dataset/runs/7q0c5wey</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:0=(0.005, 8, 1000, (3, 3), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 1.0179,Accuracy: 86.338\n",
      "Epoch [2/8], Loss: 0.7320,Accuracy: 87.708\n",
      "Epoch [3/8], Loss: 0.6016,Accuracy: 87.964\n",
      "Epoch [4/8], Loss: 0.6394,Accuracy: 88.314\n",
      "Epoch [5/8], Loss: 0.5175,Accuracy: 88.588\n",
      "Epoch [6/8], Loss: 0.4861,Accuracy: 88.61\n",
      "Epoch [7/8], Loss: 0.4855,Accuracy: 88.626\n",
      "Epoch [8/8], Loss: 0.4495,Accuracy: 88.724\n",
      "Hyperparameters:1=(0.005, 8, 1000, (3, 3), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 1.4364,Accuracy: 84.256\n",
      "Epoch [2/8], Loss: 1.0654,Accuracy: 86.496\n",
      "Epoch [3/8], Loss: 0.8825,Accuracy: 87.144\n",
      "Epoch [4/8], Loss: 0.7937,Accuracy: 87.718\n",
      "Epoch [5/8], Loss: 0.6694,Accuracy: 87.816\n",
      "Epoch [6/8], Loss: 0.7062,Accuracy: 87.544\n",
      "Epoch [7/8], Loss: 0.6545,Accuracy: 88.018\n",
      "Epoch [8/8], Loss: 0.6792,Accuracy: 88.136\n",
      "Hyperparameters:2=(0.005, 8, 1000, (5, 5), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 1.8727,Accuracy: 79.776\n",
      "Epoch [2/8], Loss: 0.9049,Accuracy: 86.974\n",
      "Epoch [3/8], Loss: 0.7113,Accuracy: 87.828\n",
      "Epoch [4/8], Loss: 0.5700,Accuracy: 88.128\n",
      "Epoch [5/8], Loss: 0.5179,Accuracy: 88.398\n",
      "Epoch [6/8], Loss: 0.5106,Accuracy: 88.502\n",
      "Epoch [7/8], Loss: 0.5096,Accuracy: 88.608\n",
      "Epoch [8/8], Loss: 0.4637,Accuracy: 88.6\n",
      "Hyperparameters:3=(0.005, 8, 1000, (5, 5), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 1.6806,Accuracy: 81.564\n",
      "Epoch [2/8], Loss: 1.1659,Accuracy: 85.296\n",
      "Epoch [3/8], Loss: 0.9470,Accuracy: 86.438\n",
      "Epoch [4/8], Loss: 0.7979,Accuracy: 87.228\n",
      "Epoch [5/8], Loss: 0.7606,Accuracy: 87.666\n",
      "Epoch [6/8], Loss: 0.7392,Accuracy: 87.966\n",
      "Epoch [7/8], Loss: 0.6000,Accuracy: 88.16\n",
      "Epoch [8/8], Loss: 0.5613,Accuracy: 88.316\n",
      "Hyperparameters:4=(0.001, 8, 1000, (3, 3), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 0.6250,Accuracy: 88.038\n",
      "Epoch [2/8], Loss: 0.4413,Accuracy: 88.806\n",
      "Epoch [3/8], Loss: 0.3921,Accuracy: 89.072\n",
      "Epoch [4/8], Loss: 0.3899,Accuracy: 89.144\n",
      "Epoch [5/8], Loss: 0.3081,Accuracy: 89.22\n",
      "Epoch [6/8], Loss: 0.3093,Accuracy: 89.24\n",
      "Epoch [7/8], Loss: 0.2945,Accuracy: 89.326\n",
      "Epoch [8/8], Loss: 0.2566,Accuracy: 89.33\n",
      "Hyperparameters:5=(0.001, 8, 1000, (3, 3), (1, 1), 0.25)\n",
      "Epoch [1/8], Loss: 0.6568,Accuracy: 87.846\n",
      "Epoch [2/8], Loss: 0.4529,Accuracy: 88.738\n",
      "Epoch [3/8], Loss: 0.3588,Accuracy: 89.034\n",
      "Epoch [4/8], Loss: 0.3632,Accuracy: 89.08\n",
      "Epoch [5/8], Loss: 0.3189,Accuracy: 89.206\n",
      "Epoch [6/8], Loss: 0.2299,Accuracy: 89.288\n",
      "Epoch [7/8], Loss: 0.2219,Accuracy: 89.298\n",
      "Epoch [8/8], Loss: 0.2741,Accuracy: 89.298\n",
      "Hyperparameters:6=(0.001, 8, 1000, (5, 5), (1, 1), 0.15)\n",
      "Epoch [1/8], Loss: 0.9068,Accuracy: 86.916\n",
      "Epoch [2/8], Loss: 0.5396,Accuracy: 88.39\n",
      "Epoch [3/8], Loss: 0.4715,Accuracy: 88.75\n",
      "Epoch [4/8], Loss: 0.3812,Accuracy: 88.9\n",
      "Epoch [5/8], Loss: 0.3965,Accuracy: 88.922\n",
      "Epoch [6/8], Loss: 0.2965,Accuracy: 89.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\5.ipynb Cell 49\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m hyper_param:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHyperparameters:\u001b[39m\u001b[39m{\u001b[39;00mJ\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     acc ,loss \u001b[39m=\u001b[39m train_CNN_model(i[\u001b[39m0\u001b[39;49m], i[\u001b[39m1\u001b[39;49m], i[\u001b[39m2\u001b[39;49m], i[\u001b[39m3\u001b[39;49m], i[\u001b[39m4\u001b[39;49m], i[\u001b[39m5\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mHyper parameters pair\u001b[39m\u001b[39m\"\u001b[39m:J,\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: acc, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: loss})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     J \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\JANAKSINH\\SMAI_Assignments\\SMAI_Assignment_3\\Q_5\\5.ipynb Cell 49\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JANAKSINH/SMAI_Assignments/SMAI_Assignment_3/Q_5/5.ipynb#Y104sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\JANAKSINH\\anaconda3\\envs\\Keras\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\JANAKSINH\\anaconda3\\envs\\Keras\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(project=\"Q-5.2.2 Hyperparameters tunining of CNN for Permuted-MNIST dataset\")\n",
    "\n",
    "from itertools import product\n",
    "h_param = {\n",
    "        'learning_rate': [0.005, 0.001],\n",
    "        'epochs' : [8],\n",
    "        'batch_size': [1000],\n",
    "        'kernel_sizes' : [(3,3),(5,5)],\n",
    "        'strides' : [(1,1)],\n",
    "        'dropout_rate' : [0.15,0.25]\n",
    "        }\n",
    "hyper_param = list(product(*h_param.values()))\n",
    "J=0\n",
    "accuracy = []\n",
    "for i in hyper_param:\n",
    "    print(f'Hyperparameters:{J}={i}')\n",
    "    acc ,loss = train_CNN_model(i[0], i[1], i[2], i[3], i[4], i[5])\n",
    "    wandb.log({\"Hyper parameters pair\":J,\"accuracy\": acc, \"loss\": loss})\n",
    "    \n",
    "    J += 1\n",
    "    accuracy.append(acc)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy4 = 89.33\n",
      "We get this accuracy for this hyperparameters\n",
      "(learning_rate,epochs,batch_size,kernel_sizes,strides,dropout_rate): (0.001, 8, 1000, (3, 3), (1, 1), 0.15).\n"
     ]
    }
   ],
   "source": [
    "Max_accu_hy_param_index = 56\n",
    "Max_accu_hy_param_index = np.argmax(accuracy)\n",
    "print(f\"The maximum accuracy{Max_accu_hy_param_index} = {accuracy[Max_accu_hy_param_index]}\")\n",
    "print(f\"We get this accuracy for this hyperparameters\\n(learning_rate,epochs,batch_size,kernel_sizes,strides,dropout_rate): {hyper_param[Max_accu_hy_param_index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2 Evaluate the model for best hyperpameter on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:6=(0.001, 8, 1000, (3, 3), (1, 1), 0.15)\n",
      "Epoch [1/3], Loss: 0.5596,Accuracy: 88.438\n"
     ]
    }
   ],
   "source": [
    "i = hyper_param[Max_accu_hy_param_index]\n",
    "print(f'Hyperparameters:{J}={i}')\n",
    "acc ,loss = train_CNN_model(i[0],3, i[2], i[3], i[4], i[5])\n",
    "print(f\"Accuracy and loss on the test dataset for best hyperparameters is :\")\n",
    "print(\"Accuracy:\",acc,\" Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_5.3  Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-1. Contrast the performances of MLP vs. CNN for both datasets      \n",
    "Answer:      \n",
    "1. CNN is giving better performance for the complex image dataset.(for the Double-MNIST dataset the CNN(89%) give better accuracy then MLP(56%)).\n",
    "2. for complex dataset MLP have more problem of overfitting compare to CNN.\n",
    "3. for the permuted dataset CNN and MLP both give similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-2. Discuss the observed differences and any challenges faced during training\n",
    "and evaluation.        \n",
    "Answer:\n",
    "1. CNN required more computational resources compare to MLP. So, for hyper parameter tuning CNN take more time.\n",
    "2. Due to low computational resources the process crashed many time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-3. Compare the potential for overfitting between a CNN and an MLP in the\n",
    "context of datasets in Task 5. Use training vs. validation loss/accuracy\n",
    "plots to support your observations.               \n",
    "Answer:    \n",
    "For the Double-MNIST dataset MLP have more overfitting problem compare to CNN, which i observed in the task 5.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
